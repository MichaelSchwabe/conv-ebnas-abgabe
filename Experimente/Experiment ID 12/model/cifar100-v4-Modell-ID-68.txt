Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
separable_conv2d_160 (Separa (None, 32, 32, 512)       2075      
_________________________________________________________________
batch_normalization_144 (Bat (None, 32, 32, 512)       2048      
_________________________________________________________________
activation_217 (Activation)  (None, 32, 32, 512)       0         
_________________________________________________________________
dropout_217 (Dropout)        (None, 32, 32, 512)       0         
_________________________________________________________________
separable_conv2d_161 (Separa (None, 32, 32, 64)        37440     
_________________________________________________________________
batch_normalization_145 (Bat (None, 32, 32, 64)        256       
_________________________________________________________________
activation_218 (Activation)  (None, 32, 32, 64)        0         
_________________________________________________________________
dropout_218 (Dropout)        (None, 32, 32, 64)        0         
_________________________________________________________________
max_pooling2d_51 (MaxPooling (None, 16, 16, 64)        0         
_________________________________________________________________
separable_conv2d_162 (Separa (None, 16, 16, 16)        1616      
_________________________________________________________________
batch_normalization_146 (Bat (None, 16, 16, 16)        64        
_________________________________________________________________
activation_219 (Activation)  (None, 16, 16, 16)        0         
_________________________________________________________________
dropout_219 (Dropout)        (None, 16, 16, 16)        0         
_________________________________________________________________
separable_conv2d_163 (Separa (None, 16, 16, 32)        688       
_________________________________________________________________
batch_normalization_147 (Bat (None, 16, 16, 32)        128       
_________________________________________________________________
activation_220 (Activation)  (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_220 (Dropout)        (None, 16, 16, 32)        0         
_________________________________________________________________
flatten_68 (Flatten)         (None, 8192)              0         
_________________________________________________________________
dense_125 (Dense)            (None, 64)                524352    
_________________________________________________________________
activation_221 (Activation)  (None, 64)                0         
_________________________________________________________________
dropout_221 (Dropout)        (None, 64)                0         
_________________________________________________________________
dense_126 (Dense)            (None, 256)               16640     
_________________________________________________________________
batch_normalization_148 (Bat (None, 256)               1024      
_________________________________________________________________
activation_222 (Activation)  (None, 256)               0         
_________________________________________________________________
dropout_222 (Dropout)        (None, 256)               0         
_________________________________________________________________
dense_127 (Dense)            (None, 100)               25700     
=================================================================
Total params: 612,031
Trainable params: 610,271
Non-trainable params: 1,760
_________________________________________________________________
