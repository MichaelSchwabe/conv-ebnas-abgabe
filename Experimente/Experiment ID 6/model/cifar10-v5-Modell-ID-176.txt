Model: "sequential_176"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1232 (Conv2D)         (None, 32, 32, 1024)      28672     
_________________________________________________________________
activation_1576 (Activation) (None, 32, 32, 1024)      0         
_________________________________________________________________
dropout_1576 (Dropout)       (None, 32, 32, 1024)      0         
_________________________________________________________________
conv2d_1233 (Conv2D)         (None, 32, 32, 1024)      9438208   
_________________________________________________________________
activation_1577 (Activation) (None, 32, 32, 1024)      0         
_________________________________________________________________
dropout_1577 (Dropout)       (None, 32, 32, 1024)      0         
_________________________________________________________________
max_pooling2d_388 (MaxPoolin (None, 16, 16, 1024)      0         
_________________________________________________________________
conv2d_1234 (Conv2D)         (None, 16, 16, 64)        589888    
_________________________________________________________________
batch_normalization_758 (Bat (None, 16, 16, 64)        256       
_________________________________________________________________
activation_1578 (Activation) (None, 16, 16, 64)        0         
_________________________________________________________________
dropout_1578 (Dropout)       (None, 16, 16, 64)        0         
_________________________________________________________________
max_pooling2d_389 (MaxPoolin (None, 8, 8, 64)          0         
_________________________________________________________________
conv2d_1235 (Conv2D)         (None, 8, 8, 128)         73856     
_________________________________________________________________
activation_1579 (Activation) (None, 8, 8, 128)         0         
_________________________________________________________________
dropout_1579 (Dropout)       (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_1236 (Conv2D)         (None, 8, 8, 32)          36896     
_________________________________________________________________
batch_normalization_759 (Bat (None, 8, 8, 32)          128       
_________________________________________________________________
activation_1580 (Activation) (None, 8, 8, 32)          0         
_________________________________________________________________
dropout_1580 (Dropout)       (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_1237 (Conv2D)         (None, 8, 8, 1024)        295936    
_________________________________________________________________
activation_1581 (Activation) (None, 8, 8, 1024)        0         
_________________________________________________________________
dropout_1581 (Dropout)       (None, 8, 8, 1024)        0         
_________________________________________________________________
conv2d_1238 (Conv2D)         (None, 8, 8, 256)         2359552   
_________________________________________________________________
batch_normalization_760 (Bat (None, 8, 8, 256)         1024      
_________________________________________________________________
activation_1582 (Activation) (None, 8, 8, 256)         0         
_________________________________________________________________
dropout_1582 (Dropout)       (None, 8, 8, 256)         0         
_________________________________________________________________
conv2d_1239 (Conv2D)         (None, 8, 8, 1024)        2360320   
_________________________________________________________________
batch_normalization_761 (Bat (None, 8, 8, 1024)        4096      
_________________________________________________________________
activation_1583 (Activation) (None, 8, 8, 1024)        0         
_________________________________________________________________
dropout_1583 (Dropout)       (None, 8, 8, 1024)        0         
_________________________________________________________________
flatten_176 (Flatten)        (None, 65536)             0         
_________________________________________________________________
dense_520 (Dense)            (None, 64)                4194368   
_________________________________________________________________
batch_normalization_762 (Bat (None, 64)                256       
_________________________________________________________________
activation_1584 (Activation) (None, 64)                0         
_________________________________________________________________
dropout_1584 (Dropout)       (None, 64)                0         
_________________________________________________________________
dense_521 (Dense)            (None, 256)               16640     
_________________________________________________________________
batch_normalization_763 (Bat (None, 256)               1024      
_________________________________________________________________
activation_1585 (Activation) (None, 256)               0         
_________________________________________________________________
dropout_1585 (Dropout)       (None, 256)               0         
_________________________________________________________________
dense_522 (Dense)            (None, 10)                2570      
=================================================================
Total params: 19,403,690
Trainable params: 19,400,298
Non-trainable params: 3,392
_________________________________________________________________
