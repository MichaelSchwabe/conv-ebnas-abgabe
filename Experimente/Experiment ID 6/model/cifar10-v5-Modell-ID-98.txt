Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_682 (Conv2D)          (None, 32, 32, 1024)      28672     
_________________________________________________________________
batch_normalization_413 (Bat (None, 32, 32, 1024)      4096      
_________________________________________________________________
activation_882 (Activation)  (None, 32, 32, 1024)      0         
_________________________________________________________________
dropout_882 (Dropout)        (None, 32, 32, 1024)      0         
_________________________________________________________________
conv2d_683 (Conv2D)          (None, 32, 32, 1024)      9438208   
_________________________________________________________________
activation_883 (Activation)  (None, 32, 32, 1024)      0         
_________________________________________________________________
dropout_883 (Dropout)        (None, 32, 32, 1024)      0         
_________________________________________________________________
max_pooling2d_205 (MaxPoolin (None, 16, 16, 1024)      0         
_________________________________________________________________
conv2d_684 (Conv2D)          (None, 16, 16, 64)        589888    
_________________________________________________________________
batch_normalization_414 (Bat (None, 16, 16, 64)        256       
_________________________________________________________________
activation_884 (Activation)  (None, 16, 16, 64)        0         
_________________________________________________________________
dropout_884 (Dropout)        (None, 16, 16, 64)        0         
_________________________________________________________________
max_pooling2d_206 (MaxPoolin (None, 8, 8, 64)          0         
_________________________________________________________________
conv2d_685 (Conv2D)          (None, 8, 8, 128)         73856     
_________________________________________________________________
activation_885 (Activation)  (None, 8, 8, 128)         0         
_________________________________________________________________
dropout_885 (Dropout)        (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_686 (Conv2D)          (None, 8, 8, 32)          36896     
_________________________________________________________________
batch_normalization_415 (Bat (None, 8, 8, 32)          128       
_________________________________________________________________
activation_886 (Activation)  (None, 8, 8, 32)          0         
_________________________________________________________________
dropout_886 (Dropout)        (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_687 (Conv2D)          (None, 8, 8, 1024)        295936    
_________________________________________________________________
activation_887 (Activation)  (None, 8, 8, 1024)        0         
_________________________________________________________________
dropout_887 (Dropout)        (None, 8, 8, 1024)        0         
_________________________________________________________________
conv2d_688 (Conv2D)          (None, 8, 8, 1024)        9438208   
_________________________________________________________________
batch_normalization_416 (Bat (None, 8, 8, 1024)        4096      
_________________________________________________________________
activation_888 (Activation)  (None, 8, 8, 1024)        0         
_________________________________________________________________
dropout_888 (Dropout)        (None, 8, 8, 1024)        0         
_________________________________________________________________
flatten_98 (Flatten)         (None, 65536)             0         
_________________________________________________________________
dense_298 (Dense)            (None, 64)                4194368   
_________________________________________________________________
batch_normalization_417 (Bat (None, 64)                256       
_________________________________________________________________
activation_889 (Activation)  (None, 64)                0         
_________________________________________________________________
dropout_889 (Dropout)        (None, 64)                0         
_________________________________________________________________
dense_299 (Dense)            (None, 256)               16640     
_________________________________________________________________
activation_890 (Activation)  (None, 256)               0         
_________________________________________________________________
dropout_890 (Dropout)        (None, 256)               0         
_________________________________________________________________
dense_300 (Dense)            (None, 10)                2570      
=================================================================
Total params: 24,124,074
Trainable params: 24,119,658
Non-trainable params: 4,416
_________________________________________________________________
