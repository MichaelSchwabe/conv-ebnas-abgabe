Model: "sequential_198"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1395 (Conv2D)         (None, 32, 32, 1024)      28672     
_________________________________________________________________
activation_1783 (Activation) (None, 32, 32, 1024)      0         
_________________________________________________________________
dropout_1783 (Dropout)       (None, 32, 32, 1024)      0         
_________________________________________________________________
conv2d_1396 (Conv2D)         (None, 32, 32, 1024)      9438208   
_________________________________________________________________
activation_1784 (Activation) (None, 32, 32, 1024)      0         
_________________________________________________________________
dropout_1784 (Dropout)       (None, 32, 32, 1024)      0         
_________________________________________________________________
max_pooling2d_432 (MaxPoolin (None, 16, 16, 1024)      0         
_________________________________________________________________
conv2d_1397 (Conv2D)         (None, 16, 16, 64)        589888    
_________________________________________________________________
batch_normalization_877 (Bat (None, 16, 16, 64)        256       
_________________________________________________________________
activation_1785 (Activation) (None, 16, 16, 64)        0         
_________________________________________________________________
dropout_1785 (Dropout)       (None, 16, 16, 64)        0         
_________________________________________________________________
max_pooling2d_433 (MaxPoolin (None, 8, 8, 64)          0         
_________________________________________________________________
conv2d_1398 (Conv2D)         (None, 8, 8, 128)         73856     
_________________________________________________________________
activation_1786 (Activation) (None, 8, 8, 128)         0         
_________________________________________________________________
dropout_1786 (Dropout)       (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_1399 (Conv2D)         (None, 8, 8, 32)          36896     
_________________________________________________________________
batch_normalization_878 (Bat (None, 8, 8, 32)          128       
_________________________________________________________________
activation_1787 (Activation) (None, 8, 8, 32)          0         
_________________________________________________________________
dropout_1787 (Dropout)       (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_1400 (Conv2D)         (None, 8, 8, 1024)        295936    
_________________________________________________________________
batch_normalization_879 (Bat (None, 8, 8, 1024)        4096      
_________________________________________________________________
activation_1788 (Activation) (None, 8, 8, 1024)        0         
_________________________________________________________________
dropout_1788 (Dropout)       (None, 8, 8, 1024)        0         
_________________________________________________________________
conv2d_1401 (Conv2D)         (None, 8, 8, 1024)        9438208   
_________________________________________________________________
batch_normalization_880 (Bat (None, 8, 8, 1024)        4096      
_________________________________________________________________
activation_1789 (Activation) (None, 8, 8, 1024)        0         
_________________________________________________________________
dropout_1789 (Dropout)       (None, 8, 8, 1024)        0         
_________________________________________________________________
flatten_198 (Flatten)        (None, 65536)             0         
_________________________________________________________________
dense_586 (Dense)            (None, 64)                4194368   
_________________________________________________________________
batch_normalization_881 (Bat (None, 64)                256       
_________________________________________________________________
activation_1790 (Activation) (None, 64)                0         
_________________________________________________________________
dropout_1790 (Dropout)       (None, 64)                0         
_________________________________________________________________
dense_587 (Dense)            (None, 256)               16640     
_________________________________________________________________
activation_1791 (Activation) (None, 256)               0         
_________________________________________________________________
dropout_1791 (Dropout)       (None, 256)               0         
_________________________________________________________________
dense_588 (Dense)            (None, 10)                2570      
=================================================================
Total params: 24,124,074
Trainable params: 24,119,658
Non-trainable params: 4,416
_________________________________________________________________
