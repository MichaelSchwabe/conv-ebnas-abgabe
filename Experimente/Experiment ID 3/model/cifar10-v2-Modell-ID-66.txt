Model: "sequential_66"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_355 (Conv2D)          (None, 32, 32, 256)       7168      
_________________________________________________________________
batch_normalization_230 (Bat (None, 32, 32, 256)       1024      
_________________________________________________________________
activation_469 (Activation)  (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_469 (Dropout)        (None, 32, 32, 256)       0         
_________________________________________________________________
max_pooling2d_129 (MaxPoolin (None, 16, 16, 256)       0         
_________________________________________________________________
conv2d_356 (Conv2D)          (None, 16, 16, 128)       295040    
_________________________________________________________________
activation_470 (Activation)  (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_470 (Dropout)        (None, 16, 16, 128)       0         
_________________________________________________________________
max_pooling2d_130 (MaxPoolin (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_357 (Conv2D)          (None, 8, 8, 128)         147584    
_________________________________________________________________
activation_471 (Activation)  (None, 8, 8, 128)         0         
_________________________________________________________________
dropout_471 (Dropout)        (None, 8, 8, 128)         0         
_________________________________________________________________
max_pooling2d_131 (MaxPoolin (None, 4, 4, 128)         0         
_________________________________________________________________
conv2d_358 (Conv2D)          (None, 4, 4, 16)          18448     
_________________________________________________________________
activation_472 (Activation)  (None, 4, 4, 16)          0         
_________________________________________________________________
dropout_472 (Dropout)        (None, 4, 4, 16)          0         
_________________________________________________________________
conv2d_359 (Conv2D)          (None, 4, 4, 128)         18560     
_________________________________________________________________
activation_473 (Activation)  (None, 4, 4, 128)         0         
_________________________________________________________________
dropout_473 (Dropout)        (None, 4, 4, 128)         0         
_________________________________________________________________
conv2d_360 (Conv2D)          (None, 4, 4, 16)          18448     
_________________________________________________________________
batch_normalization_231 (Bat (None, 4, 4, 16)          64        
_________________________________________________________________
activation_474 (Activation)  (None, 4, 4, 16)          0         
_________________________________________________________________
dropout_474 (Dropout)        (None, 4, 4, 16)          0         
_________________________________________________________________
flatten_66 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_180 (Dense)            (None, 128)               32896     
_________________________________________________________________
activation_475 (Activation)  (None, 128)               0         
_________________________________________________________________
dropout_475 (Dropout)        (None, 128)               0         
_________________________________________________________________
dense_181 (Dense)            (None, 10)                1290      
=================================================================
Total params: 540,522
Trainable params: 539,978
Non-trainable params: 544
_________________________________________________________________
