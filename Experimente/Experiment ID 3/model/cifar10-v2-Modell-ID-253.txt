Model: "sequential_253"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1505 (Conv2D)         (None, 32, 32, 16)        448       
_________________________________________________________________
batch_normalization_746 (Bat (None, 32, 32, 16)        64        
_________________________________________________________________
activation_1856 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_1856 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_1506 (Conv2D)         (None, 32, 32, 128)       18560     
_________________________________________________________________
batch_normalization_747 (Bat (None, 32, 32, 128)       512       
_________________________________________________________________
activation_1857 (Activation) (None, 32, 32, 128)       0         
_________________________________________________________________
dropout_1857 (Dropout)       (None, 32, 32, 128)       0         
_________________________________________________________________
max_pooling2d_474 (MaxPoolin (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_1507 (Conv2D)         (None, 16, 16, 128)       147584    
_________________________________________________________________
activation_1858 (Activation) (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_1858 (Dropout)       (None, 16, 16, 128)       0         
_________________________________________________________________
max_pooling2d_475 (MaxPoolin (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_1508 (Conv2D)         (None, 8, 8, 32)          36896     
_________________________________________________________________
activation_1859 (Activation) (None, 8, 8, 32)          0         
_________________________________________________________________
dropout_1859 (Dropout)       (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_1509 (Conv2D)         (None, 8, 8, 32)          9248      
_________________________________________________________________
activation_1860 (Activation) (None, 8, 8, 32)          0         
_________________________________________________________________
dropout_1860 (Dropout)       (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_1510 (Conv2D)         (None, 8, 8, 128)         36992     
_________________________________________________________________
activation_1861 (Activation) (None, 8, 8, 128)         0         
_________________________________________________________________
dropout_1861 (Dropout)       (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_1511 (Conv2D)         (None, 8, 8, 16)          18448     
_________________________________________________________________
batch_normalization_748 (Bat (None, 8, 8, 16)          64        
_________________________________________________________________
activation_1862 (Activation) (None, 8, 8, 16)          0         
_________________________________________________________________
dropout_1862 (Dropout)       (None, 8, 8, 16)          0         
_________________________________________________________________
flatten_253 (Flatten)        (None, 1024)              0         
_________________________________________________________________
dense_604 (Dense)            (None, 10)                10250     
=================================================================
Total params: 279,066
Trainable params: 278,746
Non-trainable params: 320
_________________________________________________________________
