Model: "sequential_386"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_2374 (Conv2D)         (None, 32, 32, 16)        448       
_________________________________________________________________
batch_normalization_1128 (Ba (None, 32, 32, 16)        64        
_________________________________________________________________
activation_2833 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_2833 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2375 (Conv2D)         (None, 32, 32, 128)       18560     
_________________________________________________________________
activation_2834 (Activation) (None, 32, 32, 128)       0         
_________________________________________________________________
dropout_2834 (Dropout)       (None, 32, 32, 128)       0         
_________________________________________________________________
max_pooling2d_689 (MaxPoolin (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_2376 (Conv2D)         (None, 16, 16, 32)        36896     
_________________________________________________________________
activation_2835 (Activation) (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_2835 (Dropout)       (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_2377 (Conv2D)         (None, 16, 16, 256)       73984     
_________________________________________________________________
activation_2836 (Activation) (None, 16, 16, 256)       0         
_________________________________________________________________
dropout_2836 (Dropout)       (None, 16, 16, 256)       0         
_________________________________________________________________
conv2d_2378 (Conv2D)         (None, 16, 16, 128)       295040    
_________________________________________________________________
activation_2837 (Activation) (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_2837 (Dropout)       (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_2379 (Conv2D)         (None, 16, 16, 16)        18448     
_________________________________________________________________
batch_normalization_1129 (Ba (None, 16, 16, 16)        64        
_________________________________________________________________
activation_2838 (Activation) (None, 16, 16, 16)        0         
_________________________________________________________________
dropout_2838 (Dropout)       (None, 16, 16, 16)        0         
_________________________________________________________________
flatten_386 (Flatten)        (None, 4096)              0         
_________________________________________________________________
dense_845 (Dense)            (None, 64)                262208    
_________________________________________________________________
batch_normalization_1130 (Ba (None, 64)                256       
_________________________________________________________________
activation_2839 (Activation) (None, 64)                0         
_________________________________________________________________
dropout_2839 (Dropout)       (None, 64)                0         
_________________________________________________________________
dense_846 (Dense)            (None, 10)                650       
=================================================================
Total params: 706,618
Trainable params: 706,426
Non-trainable params: 192
_________________________________________________________________
