Model: "sequential_248"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1472 (Conv2D)         (None, 32, 32, 16)        448       
_________________________________________________________________
batch_normalization_727 (Bat (None, 32, 32, 16)        64        
_________________________________________________________________
activation_1818 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_1818 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_1473 (Conv2D)         (None, 32, 32, 128)       18560     
_________________________________________________________________
batch_normalization_728 (Bat (None, 32, 32, 128)       512       
_________________________________________________________________
activation_1819 (Activation) (None, 32, 32, 128)       0         
_________________________________________________________________
dropout_1819 (Dropout)       (None, 32, 32, 128)       0         
_________________________________________________________________
max_pooling2d_465 (MaxPoolin (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_1474 (Conv2D)         (None, 16, 16, 128)       147584    
_________________________________________________________________
activation_1820 (Activation) (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_1820 (Dropout)       (None, 16, 16, 128)       0         
_________________________________________________________________
max_pooling2d_466 (MaxPoolin (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_1475 (Conv2D)         (None, 8, 8, 32)          36896     
_________________________________________________________________
activation_1821 (Activation) (None, 8, 8, 32)          0         
_________________________________________________________________
dropout_1821 (Dropout)       (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_1476 (Conv2D)         (None, 8, 8, 32)          9248      
_________________________________________________________________
activation_1822 (Activation) (None, 8, 8, 32)          0         
_________________________________________________________________
dropout_1822 (Dropout)       (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_1477 (Conv2D)         (None, 8, 8, 16)          4624      
_________________________________________________________________
batch_normalization_729 (Bat (None, 8, 8, 16)          64        
_________________________________________________________________
activation_1823 (Activation) (None, 8, 8, 16)          0         
_________________________________________________________________
dropout_1823 (Dropout)       (None, 8, 8, 16)          0         
_________________________________________________________________
flatten_248 (Flatten)        (None, 1024)              0         
_________________________________________________________________
dense_594 (Dense)            (None, 128)               131200    
_________________________________________________________________
activation_1824 (Activation) (None, 128)               0         
_________________________________________________________________
dropout_1824 (Dropout)       (None, 128)               0         
_________________________________________________________________
dense_595 (Dense)            (None, 10)                1290      
=================================================================
Total params: 350,490
Trainable params: 350,170
Non-trainable params: 320
_________________________________________________________________
