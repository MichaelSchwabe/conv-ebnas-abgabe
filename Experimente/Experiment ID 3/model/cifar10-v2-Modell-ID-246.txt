Model: "sequential_246"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1459 (Conv2D)         (None, 32, 32, 16)        448       
_________________________________________________________________
batch_normalization_721 (Bat (None, 32, 32, 16)        64        
_________________________________________________________________
activation_1805 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_1805 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_1460 (Conv2D)         (None, 32, 32, 128)       18560     
_________________________________________________________________
batch_normalization_722 (Bat (None, 32, 32, 128)       512       
_________________________________________________________________
activation_1806 (Activation) (None, 32, 32, 128)       0         
_________________________________________________________________
dropout_1806 (Dropout)       (None, 32, 32, 128)       0         
_________________________________________________________________
max_pooling2d_460 (MaxPoolin (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_1461 (Conv2D)         (None, 16, 16, 128)       147584    
_________________________________________________________________
activation_1807 (Activation) (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_1807 (Dropout)       (None, 16, 16, 128)       0         
_________________________________________________________________
max_pooling2d_461 (MaxPoolin (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_1462 (Conv2D)         (None, 8, 8, 32)          36896     
_________________________________________________________________
activation_1808 (Activation) (None, 8, 8, 32)          0         
_________________________________________________________________
dropout_1808 (Dropout)       (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_1463 (Conv2D)         (None, 8, 8, 128)         36992     
_________________________________________________________________
activation_1809 (Activation) (None, 8, 8, 128)         0         
_________________________________________________________________
dropout_1809 (Dropout)       (None, 8, 8, 128)         0         
_________________________________________________________________
conv2d_1464 (Conv2D)         (None, 8, 8, 16)          18448     
_________________________________________________________________
batch_normalization_723 (Bat (None, 8, 8, 16)          64        
_________________________________________________________________
activation_1810 (Activation) (None, 8, 8, 16)          0         
_________________________________________________________________
dropout_1810 (Dropout)       (None, 8, 8, 16)          0         
_________________________________________________________________
flatten_246 (Flatten)        (None, 1024)              0         
_________________________________________________________________
dense_592 (Dense)            (None, 10)                10250     
=================================================================
Total params: 269,818
Trainable params: 269,498
Non-trainable params: 320
_________________________________________________________________
