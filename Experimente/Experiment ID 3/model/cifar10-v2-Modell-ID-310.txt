Model: "sequential_310"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1890 (Conv2D)         (None, 32, 32, 16)        448       
_________________________________________________________________
batch_normalization_933 (Bat (None, 32, 32, 16)        64        
_________________________________________________________________
activation_2292 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_2292 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_1891 (Conv2D)         (None, 32, 32, 512)       74240     
_________________________________________________________________
batch_normalization_934 (Bat (None, 32, 32, 512)       2048      
_________________________________________________________________
activation_2293 (Activation) (None, 32, 32, 512)       0         
_________________________________________________________________
dropout_2293 (Dropout)       (None, 32, 32, 512)       0         
_________________________________________________________________
conv2d_1892 (Conv2D)         (None, 32, 32, 128)       589952    
_________________________________________________________________
activation_2294 (Activation) (None, 32, 32, 128)       0         
_________________________________________________________________
dropout_2294 (Dropout)       (None, 32, 32, 128)       0         
_________________________________________________________________
max_pooling2d_579 (MaxPoolin (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_1893 (Conv2D)         (None, 16, 16, 512)       590336    
_________________________________________________________________
batch_normalization_935 (Bat (None, 16, 16, 512)       2048      
_________________________________________________________________
activation_2295 (Activation) (None, 16, 16, 512)       0         
_________________________________________________________________
dropout_2295 (Dropout)       (None, 16, 16, 512)       0         
_________________________________________________________________
conv2d_1894 (Conv2D)         (None, 16, 16, 256)       1179904   
_________________________________________________________________
activation_2296 (Activation) (None, 16, 16, 256)       0         
_________________________________________________________________
dropout_2296 (Dropout)       (None, 16, 16, 256)       0         
_________________________________________________________________
conv2d_1895 (Conv2D)         (None, 16, 16, 128)       295040    
_________________________________________________________________
activation_2297 (Activation) (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_2297 (Dropout)       (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_1896 (Conv2D)         (None, 16, 16, 16)        18448     
_________________________________________________________________
batch_normalization_936 (Bat (None, 16, 16, 16)        64        
_________________________________________________________________
activation_2298 (Activation) (None, 16, 16, 16)        0         
_________________________________________________________________
dropout_2298 (Dropout)       (None, 16, 16, 16)        0         
_________________________________________________________________
flatten_310 (Flatten)        (None, 4096)              0         
_________________________________________________________________
dense_712 (Dense)            (None, 10)                40970     
=================================================================
Total params: 2,793,562
Trainable params: 2,791,450
Non-trainable params: 2,112
_________________________________________________________________
