Model: "sequential_68"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
separable_conv2d_164 (Separa (None, 32, 32, 32)        155       
_________________________________________________________________
batch_normalization_66 (Batc (None, 32, 32, 32)        128       
_________________________________________________________________
activation_218 (Activation)  (None, 32, 32, 32)        0         
_________________________________________________________________
dropout_218 (Dropout)        (None, 32, 32, 32)        0         
_________________________________________________________________
max_pooling2d_56 (MaxPooling (None, 16, 16, 32)        0         
_________________________________________________________________
separable_conv2d_165 (Separa (None, 16, 16, 256)       8736      
_________________________________________________________________
activation_219 (Activation)  (None, 16, 16, 256)       0         
_________________________________________________________________
dropout_219 (Dropout)        (None, 16, 16, 256)       0         
_________________________________________________________________
separable_conv2d_166 (Separa (None, 16, 16, 32)        10528     
_________________________________________________________________
activation_220 (Activation)  (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_220 (Dropout)        (None, 16, 16, 32)        0         
_________________________________________________________________
separable_conv2d_167 (Separa (None, 16, 16, 128)       4512      
_________________________________________________________________
activation_221 (Activation)  (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_221 (Dropout)        (None, 16, 16, 128)       0         
_________________________________________________________________
flatten_68 (Flatten)         (None, 32768)             0         
_________________________________________________________________
dense_122 (Dense)            (None, 256)               8388864   
_________________________________________________________________
activation_222 (Activation)  (None, 256)               0         
_________________________________________________________________
dropout_222 (Dropout)        (None, 256)               0         
_________________________________________________________________
dense_123 (Dense)            (None, 100)               25700     
=================================================================
Total params: 8,438,623
Trainable params: 8,438,559
Non-trainable params: 64
_________________________________________________________________
