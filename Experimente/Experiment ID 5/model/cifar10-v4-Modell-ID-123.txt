Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_694 (Conv2D)          (None, 32, 32, 16)        448       
_________________________________________________________________
activation_1006 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_1006 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_695 (Conv2D)          (None, 32, 32, 128)       18560     
_________________________________________________________________
batch_normalization_480 (Bat (None, 32, 32, 128)       512       
_________________________________________________________________
activation_1007 (Activation) (None, 32, 32, 128)       0         
_________________________________________________________________
dropout_1007 (Dropout)       (None, 32, 32, 128)       0         
_________________________________________________________________
max_pooling2d_106 (MaxPoolin (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_696 (Conv2D)          (None, 16, 16, 32)        36896     
_________________________________________________________________
activation_1008 (Activation) (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_1008 (Dropout)       (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_697 (Conv2D)          (None, 16, 16, 128)       36992     
_________________________________________________________________
batch_normalization_481 (Bat (None, 16, 16, 128)       512       
_________________________________________________________________
activation_1009 (Activation) (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_1009 (Dropout)       (None, 16, 16, 128)       0         
_________________________________________________________________
flatten_123 (Flatten)        (None, 32768)             0         
_________________________________________________________________
dense_435 (Dense)            (None, 32)                1048608   
_________________________________________________________________
batch_normalization_482 (Bat (None, 32)                128       
_________________________________________________________________
activation_1010 (Activation) (None, 32)                0         
_________________________________________________________________
dropout_1010 (Dropout)       (None, 32)                0         
_________________________________________________________________
dense_436 (Dense)            (None, 256)               8448      
_________________________________________________________________
activation_1011 (Activation) (None, 256)               0         
_________________________________________________________________
dropout_1011 (Dropout)       (None, 256)               0         
_________________________________________________________________
dense_437 (Dense)            (None, 512)               131584    
_________________________________________________________________
batch_normalization_483 (Bat (None, 512)               2048      
_________________________________________________________________
activation_1012 (Activation) (None, 512)               0         
_________________________________________________________________
dropout_1012 (Dropout)       (None, 512)               0         
_________________________________________________________________
dense_438 (Dense)            (None, 10)                5130      
=================================================================
Total params: 1,289,866
Trainable params: 1,288,266
Non-trainable params: 1,600
_________________________________________________________________
