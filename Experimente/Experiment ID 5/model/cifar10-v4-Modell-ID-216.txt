Model: "sequential_216"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1065 (Conv2D)         (None, 32, 32, 16)        448       
_________________________________________________________________
activation_1565 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_1565 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_1066 (Conv2D)         (None, 32, 32, 128)       18560     
_________________________________________________________________
batch_normalization_760 (Bat (None, 32, 32, 128)       512       
_________________________________________________________________
activation_1566 (Activation) (None, 32, 32, 128)       0         
_________________________________________________________________
dropout_1566 (Dropout)       (None, 32, 32, 128)       0         
_________________________________________________________________
max_pooling2d_193 (MaxPoolin (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_1067 (Conv2D)         (None, 16, 16, 32)        36896     
_________________________________________________________________
activation_1567 (Activation) (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_1567 (Dropout)       (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_1068 (Conv2D)         (None, 16, 16, 1024)      295936    
_________________________________________________________________
batch_normalization_761 (Bat (None, 16, 16, 1024)      4096      
_________________________________________________________________
activation_1568 (Activation) (None, 16, 16, 1024)      0         
_________________________________________________________________
dropout_1568 (Dropout)       (None, 16, 16, 1024)      0         
_________________________________________________________________
flatten_216 (Flatten)        (None, 262144)            0         
_________________________________________________________________
dense_716 (Dense)            (None, 256)               67109120  
_________________________________________________________________
activation_1569 (Activation) (None, 256)               0         
_________________________________________________________________
dropout_1569 (Dropout)       (None, 256)               0         
_________________________________________________________________
dense_717 (Dense)            (None, 10)                2570      
=================================================================
Total params: 67,468,138
Trainable params: 67,465,834
Non-trainable params: 2,304
_________________________________________________________________
