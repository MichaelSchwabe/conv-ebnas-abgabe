Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_948 (Conv2D)          (None, 32, 32, 16)        448       
_________________________________________________________________
activation_1391 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_1391 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_949 (Conv2D)          (None, 32, 32, 128)       18560     
_________________________________________________________________
batch_normalization_675 (Bat (None, 32, 32, 128)       512       
_________________________________________________________________
activation_1392 (Activation) (None, 32, 32, 128)       0         
_________________________________________________________________
dropout_1392 (Dropout)       (None, 32, 32, 128)       0         
_________________________________________________________________
max_pooling2d_163 (MaxPoolin (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_950 (Conv2D)          (None, 16, 16, 32)        36896     
_________________________________________________________________
activation_1393 (Activation) (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_1393 (Dropout)       (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_951 (Conv2D)          (None, 16, 16, 1024)      295936    
_________________________________________________________________
batch_normalization_676 (Bat (None, 16, 16, 1024)      4096      
_________________________________________________________________
activation_1394 (Activation) (None, 16, 16, 1024)      0         
_________________________________________________________________
dropout_1394 (Dropout)       (None, 16, 16, 1024)      0         
_________________________________________________________________
flatten_186 (Flatten)        (None, 262144)            0         
_________________________________________________________________
dense_629 (Dense)            (None, 256)               67109120  
_________________________________________________________________
activation_1395 (Activation) (None, 256)               0         
_________________________________________________________________
dropout_1395 (Dropout)       (None, 256)               0         
_________________________________________________________________
dense_630 (Dense)            (None, 512)               131584    
_________________________________________________________________
batch_normalization_677 (Bat (None, 512)               2048      
_________________________________________________________________
activation_1396 (Activation) (None, 512)               0         
_________________________________________________________________
dropout_1396 (Dropout)       (None, 512)               0         
_________________________________________________________________
dense_631 (Dense)            (None, 10)                5130      
=================================================================
Total params: 67,604,330
Trainable params: 67,601,002
Non-trainable params: 3,328
_________________________________________________________________
