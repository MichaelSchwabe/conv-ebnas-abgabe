Model: "sequential_356"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1607 (Conv2D)         (None, 32, 32, 16)        448       
_________________________________________________________________
activation_2339 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_2339 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
max_pooling2d_332 (MaxPoolin (None, 16, 16, 16)        0         
_________________________________________________________________
conv2d_1608 (Conv2D)         (None, 16, 16, 128)       18560     
_________________________________________________________________
batch_normalization_1181 (Ba (None, 16, 16, 128)       512       
_________________________________________________________________
activation_2340 (Activation) (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_2340 (Dropout)       (None, 16, 16, 128)       0         
_________________________________________________________________
conv2d_1609 (Conv2D)         (None, 16, 16, 1024)      1180672   
_________________________________________________________________
activation_2341 (Activation) (None, 16, 16, 1024)      0         
_________________________________________________________________
dropout_2341 (Dropout)       (None, 16, 16, 1024)      0         
_________________________________________________________________
max_pooling2d_333 (MaxPoolin (None, 8, 8, 1024)        0         
_________________________________________________________________
conv2d_1610 (Conv2D)         (None, 8, 8, 1024)        9438208   
_________________________________________________________________
batch_normalization_1182 (Ba (None, 8, 8, 1024)        4096      
_________________________________________________________________
activation_2342 (Activation) (None, 8, 8, 1024)        0         
_________________________________________________________________
dropout_2342 (Dropout)       (None, 8, 8, 1024)        0         
_________________________________________________________________
flatten_356 (Flatten)        (None, 65536)             0         
_________________________________________________________________
dense_1088 (Dense)           (None, 64)                4194368   
_________________________________________________________________
batch_normalization_1183 (Ba (None, 64)                256       
_________________________________________________________________
activation_2343 (Activation) (None, 64)                0         
_________________________________________________________________
dropout_2343 (Dropout)       (None, 64)                0         
_________________________________________________________________
dense_1089 (Dense)           (None, 32)                2080      
_________________________________________________________________
batch_normalization_1184 (Ba (None, 32)                128       
_________________________________________________________________
activation_2344 (Activation) (None, 32)                0         
_________________________________________________________________
dropout_2344 (Dropout)       (None, 32)                0         
_________________________________________________________________
dense_1090 (Dense)           (None, 10)                330       
=================================================================
Total params: 14,839,658
Trainable params: 14,837,162
Non-trainable params: 2,496
_________________________________________________________________
