Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_400 (Conv2D)          (None, 32, 32, 256)       7168      
_________________________________________________________________
batch_normalization_330 (Bat (None, 32, 32, 256)       1024      
_________________________________________________________________
activation_511 (Activation)  (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_511 (Dropout)        (None, 32, 32, 256)       0         
_________________________________________________________________
conv2d_401 (Conv2D)          (None, 32, 32, 256)       590080    
_________________________________________________________________
batch_normalization_331 (Bat (None, 32, 32, 256)       1024      
_________________________________________________________________
activation_512 (Activation)  (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_512 (Dropout)        (None, 32, 32, 256)       0         
_________________________________________________________________
conv2d_402 (Conv2D)          (None, 32, 32, 1024)      2360320   
_________________________________________________________________
batch_normalization_332 (Bat (None, 32, 32, 1024)      4096      
_________________________________________________________________
activation_513 (Activation)  (None, 32, 32, 1024)      0         
_________________________________________________________________
dropout_513 (Dropout)        (None, 32, 32, 1024)      0         
_________________________________________________________________
conv2d_403 (Conv2D)          (None, 32, 32, 512)       4719104   
_________________________________________________________________
batch_normalization_333 (Bat (None, 32, 32, 512)       2048      
_________________________________________________________________
activation_514 (Activation)  (None, 32, 32, 512)       0         
_________________________________________________________________
dropout_514 (Dropout)        (None, 32, 32, 512)       0         
_________________________________________________________________
max_pooling2d_150 (MaxPoolin (None, 16, 16, 512)       0         
_________________________________________________________________
flatten_86 (Flatten)         (None, 131072)            0         
_________________________________________________________________
dense_197 (Dense)            (None, 512)               67109376  
_________________________________________________________________
activation_515 (Activation)  (None, 512)               0         
_________________________________________________________________
dropout_515 (Dropout)        (None, 512)               0         
_________________________________________________________________
dense_198 (Dense)            (None, 64)                32832     
_________________________________________________________________
batch_normalization_334 (Bat (None, 64)                256       
_________________________________________________________________
activation_516 (Activation)  (None, 64)                0         
_________________________________________________________________
dropout_516 (Dropout)        (None, 64)                0         
_________________________________________________________________
dense_199 (Dense)            (None, 10)                650       
=================================================================
Total params: 74,827,978
Trainable params: 74,823,754
Non-trainable params: 4,224
_________________________________________________________________
