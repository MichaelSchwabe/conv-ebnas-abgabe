Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_895 (Conv2D)          (None, 32, 32, 256)       7168      
_________________________________________________________________
batch_normalization_853 (Bat (None, 32, 32, 256)       1024      
_________________________________________________________________
activation_1177 (Activation) (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_1177 (Dropout)       (None, 32, 32, 256)       0         
_________________________________________________________________
conv2d_896 (Conv2D)          (None, 32, 32, 32)        73760     
_________________________________________________________________
batch_normalization_854 (Bat (None, 32, 32, 32)        128       
_________________________________________________________________
activation_1178 (Activation) (None, 32, 32, 32)        0         
_________________________________________________________________
dropout_1178 (Dropout)       (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_897 (Conv2D)          (None, 32, 32, 16)        4624      
_________________________________________________________________
batch_normalization_855 (Bat (None, 32, 32, 16)        64        
_________________________________________________________________
activation_1179 (Activation) (None, 32, 32, 16)        0         
_________________________________________________________________
dropout_1179 (Dropout)       (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_898 (Conv2D)          (None, 32, 32, 32)        4640      
_________________________________________________________________
batch_normalization_856 (Bat (None, 32, 32, 32)        128       
_________________________________________________________________
activation_1180 (Activation) (None, 32, 32, 32)        0         
_________________________________________________________________
dropout_1180 (Dropout)       (None, 32, 32, 32)        0         
_________________________________________________________________
max_pooling2d_298 (MaxPoolin (None, 16, 16, 32)        0         
_________________________________________________________________
flatten_186 (Flatten)        (None, 8192)              0         
_________________________________________________________________
dense_468 (Dense)            (None, 64)                524352    
_________________________________________________________________
batch_normalization_857 (Bat (None, 64)                256       
_________________________________________________________________
activation_1181 (Activation) (None, 64)                0         
_________________________________________________________________
dropout_1181 (Dropout)       (None, 64)                0         
_________________________________________________________________
dense_469 (Dense)            (None, 10)                650       
=================================================================
Total params: 616,794
Trainable params: 615,994
Non-trainable params: 800
_________________________________________________________________
