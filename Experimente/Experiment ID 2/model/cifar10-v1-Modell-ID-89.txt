Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_411 (Conv2D)          (None, 32, 32, 1024)      28672     
_________________________________________________________________
batch_normalization_338 (Bat (None, 32, 32, 1024)      4096      
_________________________________________________________________
activation_526 (Activation)  (None, 32, 32, 1024)      0         
_________________________________________________________________
dropout_526 (Dropout)        (None, 32, 32, 1024)      0         
_________________________________________________________________
conv2d_412 (Conv2D)          (None, 32, 32, 128)       1179776   
_________________________________________________________________
batch_normalization_339 (Bat (None, 32, 32, 128)       512       
_________________________________________________________________
activation_527 (Activation)  (None, 32, 32, 128)       0         
_________________________________________________________________
dropout_527 (Dropout)        (None, 32, 32, 128)       0         
_________________________________________________________________
conv2d_413 (Conv2D)          (None, 32, 32, 256)       295168    
_________________________________________________________________
batch_normalization_340 (Bat (None, 32, 32, 256)       1024      
_________________________________________________________________
activation_528 (Activation)  (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_528 (Dropout)        (None, 32, 32, 256)       0         
_________________________________________________________________
max_pooling2d_154 (MaxPoolin (None, 16, 16, 256)       0         
_________________________________________________________________
conv2d_414 (Conv2D)          (None, 16, 16, 256)       590080    
_________________________________________________________________
batch_normalization_341 (Bat (None, 16, 16, 256)       1024      
_________________________________________________________________
activation_529 (Activation)  (None, 16, 16, 256)       0         
_________________________________________________________________
dropout_529 (Dropout)        (None, 16, 16, 256)       0         
_________________________________________________________________
conv2d_415 (Conv2D)          (None, 16, 16, 16)        36880     
_________________________________________________________________
batch_normalization_342 (Bat (None, 16, 16, 16)        64        
_________________________________________________________________
activation_530 (Activation)  (None, 16, 16, 16)        0         
_________________________________________________________________
dropout_530 (Dropout)        (None, 16, 16, 16)        0         
_________________________________________________________________
conv2d_416 (Conv2D)          (None, 16, 16, 512)       74240     
_________________________________________________________________
batch_normalization_343 (Bat (None, 16, 16, 512)       2048      
_________________________________________________________________
activation_531 (Activation)  (None, 16, 16, 512)       0         
_________________________________________________________________
dropout_531 (Dropout)        (None, 16, 16, 512)       0         
_________________________________________________________________
max_pooling2d_155 (MaxPoolin (None, 8, 8, 512)         0         
_________________________________________________________________
conv2d_417 (Conv2D)          (None, 8, 8, 128)         589952    
_________________________________________________________________
activation_532 (Activation)  (None, 8, 8, 128)         0         
_________________________________________________________________
dropout_532 (Dropout)        (None, 8, 8, 128)         0         
_________________________________________________________________
max_pooling2d_156 (MaxPoolin (None, 4, 4, 128)         0         
_________________________________________________________________
flatten_89 (Flatten)         (None, 2048)              0         
_________________________________________________________________
dense_204 (Dense)            (None, 16)                32784     
_________________________________________________________________
batch_normalization_344 (Bat (None, 16)                64        
_________________________________________________________________
activation_533 (Activation)  (None, 16)                0         
_________________________________________________________________
dropout_533 (Dropout)        (None, 16)                0         
_________________________________________________________________
dense_205 (Dense)            (None, 512)               8704      
_________________________________________________________________
batch_normalization_345 (Bat (None, 512)               2048      
_________________________________________________________________
activation_534 (Activation)  (None, 512)               0         
_________________________________________________________________
dropout_534 (Dropout)        (None, 512)               0         
_________________________________________________________________
dense_206 (Dense)            (None, 10)                5130      
=================================================================
Total params: 2,852,266
Trainable params: 2,846,826
Non-trainable params: 5,440
_________________________________________________________________
