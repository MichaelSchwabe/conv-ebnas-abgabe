Model: "sequential_203"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
separable_conv2d_2294 (Separ (None, 32, 32, 32)        155       
_________________________________________________________________
activation_2500 (Activation) (None, 32, 32, 32)        0         
_________________________________________________________________
dropout_2500 (Dropout)       (None, 32, 32, 32)        0         
_________________________________________________________________
separable_conv2d_2295 (Separ (None, 32, 32, 256)       8736      
_________________________________________________________________
batch_normalization_1474 (Ba (None, 32, 32, 256)       1024      
_________________________________________________________________
activation_2501 (Activation) (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_2501 (Dropout)       (None, 32, 32, 256)       0         
_________________________________________________________________
separable_conv2d_2296 (Separ (None, 32, 32, 8)         4360      
_________________________________________________________________
activation_2502 (Activation) (None, 32, 32, 8)         0         
_________________________________________________________________
dropout_2502 (Dropout)       (None, 32, 32, 8)         0         
_________________________________________________________________
separable_conv2d_2297 (Separ (None, 32, 32, 64)        648       
_________________________________________________________________
activation_2503 (Activation) (None, 32, 32, 64)        0         
_________________________________________________________________
dropout_2503 (Dropout)       (None, 32, 32, 64)        0         
_________________________________________________________________
max_pooling2d_596 (MaxPoolin (None, 16, 16, 64)        0         
_________________________________________________________________
separable_conv2d_2298 (Separ (None, 16, 16, 16)        1616      
_________________________________________________________________
activation_2504 (Activation) (None, 16, 16, 16)        0         
_________________________________________________________________
dropout_2504 (Dropout)       (None, 16, 16, 16)        0         
_________________________________________________________________
separable_conv2d_2299 (Separ (None, 16, 16, 128)       2320      
_________________________________________________________________
batch_normalization_1475 (Ba (None, 16, 16, 128)       512       
_________________________________________________________________
activation_2505 (Activation) (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_2505 (Dropout)       (None, 16, 16, 128)       0         
_________________________________________________________________
separable_conv2d_2300 (Separ (None, 16, 16, 64)        9408      
_________________________________________________________________
batch_normalization_1476 (Ba (None, 16, 16, 64)        256       
_________________________________________________________________
activation_2506 (Activation) (None, 16, 16, 64)        0         
_________________________________________________________________
dropout_2506 (Dropout)       (None, 16, 16, 64)        0         
_________________________________________________________________
separable_conv2d_2301 (Separ (None, 16, 16, 32)        2656      
_________________________________________________________________
batch_normalization_1477 (Ba (None, 16, 16, 32)        128       
_________________________________________________________________
activation_2507 (Activation) (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_2507 (Dropout)       (None, 16, 16, 32)        0         
_________________________________________________________________
separable_conv2d_2302 (Separ (None, 16, 16, 512)       17184     
_________________________________________________________________
batch_normalization_1478 (Ba (None, 16, 16, 512)       2048      
_________________________________________________________________
activation_2508 (Activation) (None, 16, 16, 512)       0         
_________________________________________________________________
dropout_2508 (Dropout)       (None, 16, 16, 512)       0         
_________________________________________________________________
max_pooling2d_597 (MaxPoolin (None, 8, 8, 512)         0         
_________________________________________________________________
flatten_203 (Flatten)        (None, 32768)             0         
_________________________________________________________________
dense_409 (Dense)            (None, 2048)              67110912  
_________________________________________________________________
batch_normalization_1479 (Ba (None, 2048)              8192      
_________________________________________________________________
activation_2509 (Activation) (None, 2048)              0         
_________________________________________________________________
dropout_2509 (Dropout)       (None, 2048)              0         
_________________________________________________________________
dense_410 (Dense)            (None, 100)               204900    
=================================================================
Total params: 67,375,055
Trainable params: 67,368,975
Non-trainable params: 6,080
_________________________________________________________________
