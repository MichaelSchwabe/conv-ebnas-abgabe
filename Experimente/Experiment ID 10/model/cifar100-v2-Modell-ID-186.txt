Model: "sequential_186"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
separable_conv2d_2111 (Separ (None, 32, 32, 32)        155       
_________________________________________________________________
activation_2300 (Activation) (None, 32, 32, 32)        0         
_________________________________________________________________
dropout_2300 (Dropout)       (None, 32, 32, 32)        0         
_________________________________________________________________
separable_conv2d_2112 (Separ (None, 32, 32, 256)       8736      
_________________________________________________________________
batch_normalization_1364 (Ba (None, 32, 32, 256)       1024      
_________________________________________________________________
activation_2301 (Activation) (None, 32, 32, 256)       0         
_________________________________________________________________
dropout_2301 (Dropout)       (None, 32, 32, 256)       0         
_________________________________________________________________
separable_conv2d_2113 (Separ (None, 32, 32, 8)         4360      
_________________________________________________________________
activation_2302 (Activation) (None, 32, 32, 8)         0         
_________________________________________________________________
dropout_2302 (Dropout)       (None, 32, 32, 8)         0         
_________________________________________________________________
separable_conv2d_2114 (Separ (None, 32, 32, 64)        648       
_________________________________________________________________
activation_2303 (Activation) (None, 32, 32, 64)        0         
_________________________________________________________________
dropout_2303 (Dropout)       (None, 32, 32, 64)        0         
_________________________________________________________________
max_pooling2d_546 (MaxPoolin (None, 16, 16, 64)        0         
_________________________________________________________________
separable_conv2d_2115 (Separ (None, 16, 16, 8)         1096      
_________________________________________________________________
activation_2304 (Activation) (None, 16, 16, 8)         0         
_________________________________________________________________
dropout_2304 (Dropout)       (None, 16, 16, 8)         0         
_________________________________________________________________
separable_conv2d_2116 (Separ (None, 16, 16, 128)       1224      
_________________________________________________________________
batch_normalization_1365 (Ba (None, 16, 16, 128)       512       
_________________________________________________________________
activation_2305 (Activation) (None, 16, 16, 128)       0         
_________________________________________________________________
dropout_2305 (Dropout)       (None, 16, 16, 128)       0         
_________________________________________________________________
separable_conv2d_2117 (Separ (None, 16, 16, 64)        9408      
_________________________________________________________________
batch_normalization_1366 (Ba (None, 16, 16, 64)        256       
_________________________________________________________________
activation_2306 (Activation) (None, 16, 16, 64)        0         
_________________________________________________________________
dropout_2306 (Dropout)       (None, 16, 16, 64)        0         
_________________________________________________________________
separable_conv2d_2118 (Separ (None, 16, 16, 32)        2656      
_________________________________________________________________
batch_normalization_1367 (Ba (None, 16, 16, 32)        128       
_________________________________________________________________
activation_2307 (Activation) (None, 16, 16, 32)        0         
_________________________________________________________________
dropout_2307 (Dropout)       (None, 16, 16, 32)        0         
_________________________________________________________________
separable_conv2d_2119 (Separ (None, 16, 16, 256)       8736      
_________________________________________________________________
batch_normalization_1368 (Ba (None, 16, 16, 256)       1024      
_________________________________________________________________
activation_2308 (Activation) (None, 16, 16, 256)       0         
_________________________________________________________________
dropout_2308 (Dropout)       (None, 16, 16, 256)       0         
_________________________________________________________________
max_pooling2d_547 (MaxPoolin (None, 8, 8, 256)         0         
_________________________________________________________________
flatten_186 (Flatten)        (None, 16384)             0         
_________________________________________________________________
dense_375 (Dense)            (None, 2048)              33556480  
_________________________________________________________________
batch_normalization_1369 (Ba (None, 2048)              8192      
_________________________________________________________________
activation_2309 (Activation) (None, 2048)              0         
_________________________________________________________________
dropout_2309 (Dropout)       (None, 2048)              0         
_________________________________________________________________
dense_376 (Dense)            (None, 100)               204900    
=================================================================
Total params: 33,809,535
Trainable params: 33,803,967
Non-trainable params: 5,568
_________________________________________________________________
